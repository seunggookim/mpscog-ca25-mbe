{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotating Training Data With MTurk\n",
    "\n",
    "## Pre-requisites\n",
    "If you haven't already, you'll need to setup MTurk and AWS accounts that are linked together to use MTurk with Python. The MTurk account will be used to post tasks to the MTurk crowd and the AWS accounts will be used to connect to MTurk via API and provide access to any additional AWS resources that are needed to execute your task.\n",
    "\n",
    "1. If you don't have an AWS account already, visit https://aws.amazon.com and create an account you can use for your project.\n",
    "2. If you don't have an MTurk Requester account already, visit https://requester.mturk.com and create a new account.\n",
    "\n",
    "After you've setup your accounts, you will need to link them together. When logged into both the root of your AWS account and your MTurk account, visit https://requester.mturk.com/developer to link them together.\n",
    "\n",
    "From your AWS console create a new AWS IAM User or select an existing one you plan to use. Add the AmazonMechanicalTurkFullAccess policy to your user. Then select the Security Credentials tab and create a new Access Key, copy the Access Key and Secret Access Key for future use.\n",
    "\n",
    "If you haven't installed the awscli yet, install it with pip (pip install awscli) and configure a profile using the access key and secret key above (aws configure --profile mturk). \n",
    "\n",
    "To post tasks to MTurk for Workers to complete you will first need to add funds to your account that will be used to reward Workers. Visit https://requester.mturk.com/account to get started with as little as $1.00.\n",
    "\n",
    "We also recommend installing xmltodict as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xmltodict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Amazon Mechanical Turk allows you to post tasks for Workers to complete at https://worker.mturk.com. To post a task to\n",
    "MTurk you create an HTML form that includes the information you want them to provide. In this example we'll be asking Workers to rate the sentiment of Tweets on a scale of 1 (negative) to 10 (positive).\n",
    "\n",
    "MTurk has a Sandbox environment that can be used for testing. Workers won't work see your tasks in the Sandbox but you can log in to do them yourself to test the task interface at https://workersandbox.mturk.com. It's recommended you test first in the Sandbox to make sure your task returns the data you need before moving to the Production environment. There is no cost to use the Sandbox environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import xmltodict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_hits_in_production = True\n",
    "environments = {\n",
    "        \"production\": {\n",
    "            \"endpoint\": \"https://mturk-requester.us-east-1.amazonaws.com\",\n",
    "            \"preview\": \"https://www.mturk.com/mturk/preview\"\n",
    "        },\n",
    "        \"sandbox\": {\n",
    "            \"endpoint\": \"https://mturk-requester-sandbox.us-east-1.amazonaws.com\",\n",
    "            \"preview\": \"https://workersandbox.mturk.com/mturk/preview\"\n",
    "        },\n",
    "}\n",
    "mturk_environment = environments[\"production\"] if create_hits_in_production else environments[\"sandbox\"]\n",
    "\n",
    "client = boto3.client(\n",
    "    service_name='mturk',\n",
    "    region_name='us-east-1',\n",
    "    endpoint_url=mturk_environment['endpoint'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return your current MTurk balance if you are connected to Production.\n",
    "# If you are connected to the Sandbox it will return $10,000.\n",
    "print(client.get_account_balance()['AvailableBalance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your task\n",
    "For this project we are going to get the sentiment of a set of tweets that we plan to train a model to evaluate. We will create an MTurk Human Intelligence Task (HIT) for each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = ['in science class right now... urgh... stupid project..',\n",
    "          'hmmm what to have for breaky?... Honey on toast ',\n",
    "          'Doing home work  x',\n",
    "          'Headed out of town for a few days. Will miss my girls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MTurk accepts an XML document containing the HTML that will be displayed to Workers. Workers will see these HTML for each item tweet that is submitted. To use the HTML for this example task, download it from [here](https://s3.amazonaws.com/mturk/samples/jupyter-examples/SentimentQuestion.html) and store it in the same directory as this notebook. Within the HTML is a variable ${content} that will be replaced with a different tweet when the HIT is created.\n",
    "\n",
    "Here the HTML is loaded and inserted into the XML Document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html_layout = open('./SentimentQuestion.html', 'r').read()\n",
    "QUESTION_XML = \"\"\"<HTMLQuestion xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2011-11-11/HTMLQuestion.xsd\">\n",
    "        <HTMLContent><![CDATA[{}]]></HTMLContent>\n",
    "        <FrameHeight>650</FrameHeight>\n",
    "        </HTMLQuestion>\"\"\"\n",
    "question_xml = QUESTION_XML.format(html_layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Mechanical Turk each task is representated by a Human Intelligence Task (HIT) which is an individual item you want annotated by one or more Workers and the interface that should be displayed. The definition below requests that five Workers review each item, that the HIT remain live on the worker.mturk.com website for no more than an hour, and that Workers provide a response for each item in less than ten minutes. Each response has a reward of \\$0.05 so the total Worker reward for this task would be \\$0.25 plus \\$0.05 in MTurk fees. An appropriate title, description, keywords are also provided to let Workers know what is involved in this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TaskAttributes = {\n",
    "    'MaxAssignments': 5,                 \n",
    "    'LifetimeInSeconds': 60*60,           # How long the task will be available on the MTurk website (1 hour)\n",
    "    'AssignmentDurationInSeconds': 60*10, # How long Workers have to complete each item (10 minutes)\n",
    "    'Reward': '0.05',                     # The reward you will offer Workers for each response\n",
    "    'Title': 'Provide sentiment for a Tweet',\n",
    "    'Keywords': 'sentiment, tweet',\n",
    "    'Description': 'Rate the sentiment of a tweet on a scale of 1 to 10.'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the tasks\n",
    "Here a HIT is created for each tweet so that it can be completed by Workers. Prior to creating the HIT, the tweet is inserted into the Question XML content. The HIT Id returned for each task is stored in a results array so that we can retrieve the results later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "hit_type_id = ''\n",
    "\n",
    "for tweet in tweets:\n",
    "    response = client.create_hit(\n",
    "        **TaskAttributes,\n",
    "        Question=question_xml.replace('${content}',tweet)\n",
    "    )\n",
    "    hit_type_id = response['HIT']['HITTypeId']\n",
    "    results.append({\n",
    "        'tweet': tweet,\n",
    "        'hit_id': response['HIT']['HITId']\n",
    "    })\n",
    "    \n",
    "print(\"You can view the HITs here:\")\n",
    "print(mturk_environment['preview'] + \"?groupId={}\".format(hit_type_id))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Results\n",
    "Depending on the task, results will be available anywhere from a few minutes to a few hours. Here we retrieve the status of each HIT and the responses that have been provided by Workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in results:\n",
    "    \n",
    "    # Get the status of the HIT\n",
    "    hit = client.get_hit(HITId=item['hit_id'])\n",
    "    item['status'] = hit['HIT']['HITStatus']\n",
    "\n",
    "    # Get a list of the Assignments that have been submitted by Workers\n",
    "    assignmentsList = client.list_assignments_for_hit(\n",
    "        HITId=item['hit_id'],\n",
    "        AssignmentStatuses=['Submitted', 'Approved'],\n",
    "        MaxResults=10\n",
    "    )\n",
    "\n",
    "    assignments = assignmentsList['Assignments']\n",
    "    item['assignments_submitted_count'] = len(assignments)\n",
    "\n",
    "    answers = []\n",
    "    for assignment in assignments:\n",
    "    \n",
    "        # Retreive the attributes for each Assignment\n",
    "        worker_id = assignment['WorkerId']\n",
    "        assignment_id = assignment['AssignmentId']\n",
    "        \n",
    "        # Retrieve the value submitted by the Worker from the XML\n",
    "        answer_dict = xmltodict.parse(assignment['Answer'])\n",
    "        answer = answer_dict['QuestionFormAnswers']['Answer']['FreeText']\n",
    "        answers.append(int(answer))\n",
    "        \n",
    "        # Approve the Assignment (if it hasn't already been approved)\n",
    "        if assignment['AssignmentStatus'] == 'Submitted':\n",
    "            client.approve_assignment(\n",
    "                AssignmentId=assignment_id,\n",
    "                OverrideRejection=False\n",
    "            )\n",
    "    \n",
    "    # Add the answers that have been retrieved for this item\n",
    "    item['answers'] = answers\n",
    "    if len(answers) > 0:\n",
    "        item['avg_answer'] = sum(answers)/len(answers)\n",
    "\n",
    "print(json.dumps(results,indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
